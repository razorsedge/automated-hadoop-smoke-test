Smoke test for HDFS
/user/SmokeTest/smoketestOutDemo path not exists !!
no path exists
Found 11 items
drwxrwxrwt   - yarn   hadoop          0 2019-04-19 12:33 /app-logs
drwxr-xr-x   - hdfs   hdfs            0 2019-04-18 19:27 /apps
drwxr-xr-x   - yarn   hadoop          0 2019-04-16 15:11 /ats
drwxr-xr-x   - hdfs   hdfs            0 2019-04-16 15:11 /atsv2
drwxr-xr-x   - hdfs   hdfs            0 2019-04-16 15:11 /hdp
drwxr-xr-x   - mapred hdfs            0 2019-04-16 15:11 /mapred
drwxrwxrwx   - mapred hadoop          0 2019-04-16 15:11 /mr-history
drwxrwxrwx   - spark  hadoop          0 2019-04-22 09:10 /spark2-history
drwxrwxrwx   - hdfs   hdfs            0 2019-04-19 13:55 /tmp
drwxrwxr-x+  - hdfs   hdfs            0 2019-04-19 09:49 /user
drwxr-xr-x   - hdfs   hdfs            0 2019-04-16 15:13 /warehouse
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
172.16.0.34	hortonworks.master
172.16.0.27     metastore.db
******************************************************************************************************************************************
Smoke test for HIVE
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/hdp/3.1.0.0-78/hive/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/hdp/3.1.0.0-78/hadoop/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://hortonworks.master:10000/
Connected to: Apache Hive (version 3.1.0.3.1.0.0-78)
Driver: Hive JDBC (version 3.1.0.3.1.0.0-78)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20190422091101_0f8db011-a681-4035-8f97-104e103ea10a): CREATE TABLE test(id INT, name STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY ' ' STORED AS TEXTFILE
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20190422091101_0f8db011-a681-4035-8f97-104e103ea10a); Time taken: 0.078 seconds
INFO  : Executing command(queryId=hive_20190422091101_0f8db011-a681-4035-8f97-104e103ea10a): CREATE TABLE test(id INT, name STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY ' ' STORED AS TEXTFILE
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20190422091101_0f8db011-a681-4035-8f97-104e103ea10a); Time taken: 0.205 seconds
INFO  : OK
No rows affected (0.455 seconds)
Beeline version 3.1.0.3.1.0.0-78 by Apache Hive
Closing: 0: jdbc:hive2://hortonworks.master:10000/
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/hdp/3.1.0.0-78/hive/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/hdp/3.1.0.0-78/hadoop/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://hortonworks.master:10000/
Connected to: Apache Hive (version 3.1.0.3.1.0.0-78)
Driver: Hive JDBC (version 3.1.0.3.1.0.0-78)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20190422091107_cfba90a0-a2a5-4892-a47d-f51c571200c6): SELECT * FROM test WHERE id=1
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:test.id, type:int, comment:null), FieldSchema(name:test.name, type:string, comment:null)], properties:null)
INFO  : Completed compiling command(queryId=hive_20190422091107_cfba90a0-a2a5-4892-a47d-f51c571200c6); Time taken: 0.265 seconds
INFO  : Executing command(queryId=hive_20190422091107_cfba90a0-a2a5-4892-a47d-f51c571200c6): SELECT * FROM test WHERE id=1
INFO  : Completed executing command(queryId=hive_20190422091107_cfba90a0-a2a5-4892-a47d-f51c571200c6); Time taken: 0.006 seconds
INFO  : OK
+----------+------------+
| test.id  | test.name  |
+----------+------------+
| 1        | justin     |
+----------+------------+
1 row selected (0.465 seconds)
Beeline version 3.1.0.3.1.0.0-78 by Apache Hive
Closing: 0: jdbc:hive2://hortonworks.master:10000/
******************************************************************************************************************************************
Smoke test for HBASE
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/hdp/3.1.0.0-78/phoenix/phoenix-5.0.0.3.1.0.0-78-server.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/hdp/3.1.0.0-78/hadoop/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Created table test
Took 2.9376 seconds
TABLE
test
1 row(s)
Took 0.0157 seconds
Took 0.1787 seconds
ROW  COLUMN+CELL
 row1 column=cf:a, timestamp=1555904479761, value=value1
1 row(s)
Took 0.0289 seconds
******************************************************************************************************************************************
Smoke Test for Yarn
19/04/22 09:11:21 INFO fs.TrashPolicyDefault: Moved: 'hdfs://hortonworks.master:8020/user/SmokeTest/MapReduce' to trash at: hdfs://hortonworks.master:8020/user/hdfs/.Trash/Current/user/SmokeTest/MapReduce
19/04/22 09:11:23 INFO client.RMProxy: Connecting to ResourceManager at hortonworks.master/172.16.0.34:8050
19/04/22 09:11:23 INFO client.AHSProxy: Connecting to Application History server at hortonworks.master/172.16.0.34:10200
19/04/22 09:11:23 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /user/yarn/.staging/job_1555599163303_0119
19/04/22 09:11:24 INFO input.FileInputFormat: Total input files to process : 1
19/04/22 09:11:24 INFO mapreduce.JobSubmitter: number of splits:1
19/04/22 09:11:24 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1555599163303_0119
19/04/22 09:11:24 INFO mapreduce.JobSubmitter: Executing with tokens: []
19/04/22 09:11:24 INFO conf.Configuration: found resource resource-types.xml at file:/etc/hadoop/3.1.0.0-78/0/resource-types.xml
19/04/22 09:11:24 INFO impl.YarnClientImpl: Submitted application application_1555599163303_0119
19/04/22 09:11:24 INFO mapreduce.Job: The url to track the job: http://hortonworks.master:8088/proxy/application_1555599163303_0119/
19/04/22 09:11:24 INFO mapreduce.Job: Running job: job_1555599163303_0119
19/04/22 09:11:31 INFO mapreduce.Job: Job job_1555599163303_0119 running in uber mode : false
19/04/22 09:11:31 INFO mapreduce.Job:  map 0% reduce 0%
19/04/22 09:11:38 INFO mapreduce.Job:  map 100% reduce 0%
19/04/22 09:12:01 INFO mapreduce.Job:  map 100% reduce 100%
19/04/22 09:12:02 INFO mapreduce.Job: Job job_1555599163303_0119 completed successfully
19/04/22 09:12:02 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=102
		FILE: Number of bytes written=464951
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=170
		HDFS: Number of bytes written=40
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=9406
		Total time spent by all reduces in occupied slots (ms)=41986
		Total time spent by all map tasks (ms)=4703
		Total time spent by all reduce tasks (ms)=20993
		Total vcore-milliseconds taken by all map tasks=4703
		Total vcore-milliseconds taken by all reduce tasks=20993
		Total megabyte-milliseconds taken by all map tasks=9631744
		Total megabyte-milliseconds taken by all reduce tasks=42993664
	Map-Reduce Framework
		Map input records=2
		Map output records=9
		Map output bytes=78
		Map output materialized bytes=102
		Input split bytes=128
		Combine input records=0
		Combine output records=0
		Reduce input groups=6
		Reduce shuffle bytes=102
		Reduce input records=9
		Reduce output records=6
		Spilled Records=18
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=130
		CPU time spent (ms)=2060
		Physical memory (bytes) snapshot=1259917312
		Virtual memory (bytes) snapshot=6954180608
		Total committed heap usage (bytes)=1146093568
		Peak Map Physical memory (bytes)=1098309632
		Peak Map Virtual memory (bytes)=3237355520
		Peak Reduce Physical memory (bytes)=161607680
		Peak Reduce Virtual memory (bytes)=3716825088
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=42
	File Output Format Counters 
		Bytes Written=40
******************************************************************************************************************************************
Smoke test for KAFKA
Created topic "test".
Here Starts the producer...!!! 
Please enter data ... cntrl+c for exit
>>>>Here Starts the Consuming...!!! 
Check log for  Data... cntrl+c for exit
asd
123
@#$
Processed a total of 3 messages
******************************************************************************************************************************************
Smoke test for SPARK
SmokeTest.sh: line 50: /user/SmokeTest/SparkIn: No such file or directory
put: `/user/SmokeTest/SparkIn': File exists
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
Spark context Web UI available at http://hortonworks.master:4040
Spark context available as 'sc' (master = yarn, app id = application_1555599163303_0120).
Spark session available as 'spark'.
Loading piEstimation.scala...
[Stage 0:>                                                          (0 + 1) / 2]                                                                                count: Long = 10
Pi is roughly 4.0
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
Spark context Web UI available at http://hortonworks.master:4040
Spark context available as 'sc' (master = yarn, app id = application_1555599163303_0121).
Spark session available as 'spark'.
Loading wordcount.scala...
args: Array[String] = Array(/user/SmokeTest/SparkIn, /user/SmokeTest/SparkOut)
input : /user/SmokeTest/SparkIn
output : /user/SmokeTest/SparkOut
file: org.apache.spark.rdd.RDD[String] = /user/SmokeTest/SparkIn MapPartitionsRDD[1] at textFile at <console>:26
counts: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[4] at reduceByKey at <console>:25
[Stage 0:>                                                          (0 + 1) / 2]                                                                                ******************************************************************************************************************************************
hdfs
19/04/22 09:15:03 INFO fs.TrashPolicyDefault: Moved: 'hdfs://hortonworks.master:8020/user/SmokeTest/smoketestOutDemo' to trash at: hdfs://hortonworks.master:8020/user/hdfs/.Trash/Current/user/SmokeTest/smoketestOutDemo
******************************************************************************************************************************************
hive
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/hdp/3.1.0.0-78/hive/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/hdp/3.1.0.0-78/hadoop/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://hortonworks.master:10000
Connected to: Apache Hive (version 3.1.0.3.1.0.0-78)
Driver: Hive JDBC (version 3.1.0.3.1.0.0-78)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20190422091506_57b35b57-ab31-4d91-bd6b-78f891bab84a): DROP TABLE test
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20190422091506_57b35b57-ab31-4d91-bd6b-78f891bab84a); Time taken: 0.095 seconds
INFO  : Executing command(queryId=hive_20190422091506_57b35b57-ab31-4d91-bd6b-78f891bab84a): DROP TABLE test
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20190422091506_57b35b57-ab31-4d91-bd6b-78f891bab84a); Time taken: 0.185 seconds
INFO  : OK
No rows affected (0.492 seconds)
Beeline version 3.1.0.3.1.0.0-78 by Apache Hive
Closing: 0: jdbc:hive2://hortonworks.master:10000
******************************************************************************************************************************************
hbase
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/hdp/3.1.0.0-78/phoenix/phoenix-5.0.0.3.1.0.0-78-server.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/hdp/3.1.0.0-78/hadoop/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Took 3.4504 seconds
Took 1.4211 seconds
******************************************************************************************************************************************
spark
19/04/22 09:15:24 INFO fs.TrashPolicyDefault: Moved: 'hdfs://hortonworks.master:8020/user/SmokeTest/SparkOut' to trash at: hdfs://hortonworks.master:8020/user/hdfs/.Trash/Current/user/SmokeTest/SparkOut
******************************************************************************************************************************************
pig
rm: `/user/SmokeTest/pigOut': No such file or directory
******************************************************************************************************************************************
kafka
Topic test is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.
/user/SmokeTest/smoketestOutDemo path not exists !!
Found 11 items
drwxrwxrwt   - yarn   hadoop          0 2019-04-19 12:33 /app-logs
drwxr-xr-x   - hdfs   hdfs            0 2019-04-18 19:27 /apps
drwxr-xr-x   - yarn   hadoop          0 2019-04-16 15:11 /ats
drwxr-xr-x   - hdfs   hdfs            0 2019-04-16 15:11 /atsv2
drwxr-xr-x   - hdfs   hdfs            0 2019-04-16 15:11 /hdp
drwxr-xr-x   - mapred hdfs            0 2019-04-16 15:11 /mapred
drwxrwxrwx   - mapred hadoop          0 2019-04-16 15:11 /mr-history
drwxrwxrwx   - spark  hadoop          0 2019-04-22 18:03 /spark2-history
drwxrwxrwx   - hdfs   hdfs            0 2019-04-19 13:55 /tmp
drwxrwxr-x+  - hdfs   hdfs            0 2019-04-19 09:49 /user
drwxr-xr-x   - hdfs   hdfs            0 2019-04-16 15:13 /warehouse
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
172.16.0.34	hortonworks.master
172.16.0.27     metastore.db
+----------+------------+
| test.id  | test.name  |
+----------+------------+
| 1        | justin     |
+----------+------------+
Smoke test for HDFS
[/user/SmokeTest/smoketestOutDemo] exists on HDFS
-rw-r--r--   3 root hdfs        218 2019-04-22 18:04 /user/SmokeTest/smoketestOutDemo
******************************************************************************************************************************************
Smoke test for HIVE
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/hdp/3.1.0.0-78/hive/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/hdp/3.1.0.0-78/hadoop/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://hortonworks.master:10000/
Connected to: Apache Hive (version 3.1.0.3.1.0.0-78)
Driver: Hive JDBC (version 3.1.0.3.1.0.0-78)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20190422182744_dc0b8899-a8e7-4c74-b766-11c7752be2d1): CREATE TABLE test(id INT, name STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY ' ' STORED AS TEXTFILE
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=hive_20190422182744_dc0b8899-a8e7-4c74-b766-11c7752be2d1); Time taken: 0.062 seconds
INFO  : Executing command(queryId=hive_20190422182744_dc0b8899-a8e7-4c74-b766-11c7752be2d1): CREATE TABLE test(id INT, name STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY ' ' STORED AS TEXTFILE
INFO  : Starting task [Stage-0:DDL] in serial mode
ERROR : FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. AlreadyExistsException(message:Table hive.default.test already exists)
INFO  : Completed executing command(queryId=hive_20190422182744_dc0b8899-a8e7-4c74-b766-11c7752be2d1); Time taken: 0.032 seconds
Error: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. AlreadyExistsException(message:Table hive.default.test already exists) (state=08S01,code=1)
Closing: 0: jdbc:hive2://hortonworks.master:10000/
put: `/warehouse/tablespace/managed/hive/test/test1.txt': File exists
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/hdp/3.1.0.0-78/hive/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/hdp/3.1.0.0-78/hadoop/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://hortonworks.master:10000/
Connected to: Apache Hive (version 3.1.0.3.1.0.0-78)
Driver: Hive JDBC (version 3.1.0.3.1.0.0-78)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20190422182749_4383ef8b-57bb-490a-8722-c7d0fcbfb3df): SELECT * FROM test WHERE id=1
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:test.id, type:int, comment:null), FieldSchema(name:test.name, type:string, comment:null)], properties:null)
INFO  : Completed compiling command(queryId=hive_20190422182749_4383ef8b-57bb-490a-8722-c7d0fcbfb3df); Time taken: 0.233 seconds
INFO  : Executing command(queryId=hive_20190422182749_4383ef8b-57bb-490a-8722-c7d0fcbfb3df): SELECT * FROM test WHERE id=1
INFO  : Completed executing command(queryId=hive_20190422182749_4383ef8b-57bb-490a-8722-c7d0fcbfb3df); Time taken: 0.004 seconds
INFO  : OK
+----------+------------+
| test.id  | test.name  |
+----------+------------+
| 1        | justin     |
+----------+------------+
1 row selected (0.492 seconds)
Beeline version 3.1.0.3.1.0.0-78 by Apache Hive
Closing: 0: jdbc:hive2://hortonworks.master:10000/
******************************************************************************************************************************************
Smoke test for HBASE
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/hdp/3.1.0.0-78/phoenix/phoenix-5.0.0.3.1.0.0-78-server.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/hdp/3.1.0.0-78/hadoop/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Created table test
Took 3.1977 seconds
TABLE
test
1 row(s)
Took 0.0249 seconds
Took 0.3787 seconds
ROW  COLUMN+CELL
 row1 column=cf:a, timestamp=1555937881424, value=value1
1 row(s)
Took 0.0256 seconds
******************************************************************************************************************************************
Smoke Test for Yarn
rm: `/user/SmokeTest/MapReduce/': No such file or directory
19/04/22 18:28:05 INFO client.RMProxy: Connecting to ResourceManager at hortonworks.master/172.16.0.34:8050
19/04/22 18:28:05 INFO client.AHSProxy: Connecting to Application History server at hortonworks.master/172.16.0.34:10200
19/04/22 18:28:06 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /user/yarn/.staging/job_1555599163303_0123
19/04/22 18:28:06 INFO input.FileInputFormat: Total input files to process : 1
19/04/22 18:28:06 INFO mapreduce.JobSubmitter: number of splits:1
19/04/22 18:28:06 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1555599163303_0123
19/04/22 18:28:06 INFO mapreduce.JobSubmitter: Executing with tokens: []
19/04/22 18:28:07 INFO conf.Configuration: found resource resource-types.xml at file:/etc/hadoop/3.1.0.0-78/0/resource-types.xml
19/04/22 18:28:07 INFO impl.YarnClientImpl: Submitted application application_1555599163303_0123
19/04/22 18:28:07 INFO mapreduce.Job: The url to track the job: http://hortonworks.master:8088/proxy/application_1555599163303_0123/
19/04/22 18:28:07 INFO mapreduce.Job: Running job: job_1555599163303_0123
